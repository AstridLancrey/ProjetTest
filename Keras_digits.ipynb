{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# chargement du dataset mnist de keras pour entraîner le cnn à la reconnaissance d'images\n",
    "\n",
    "Le dataset mnist fourni par keras est un set de **60 000 images** d'un chiffre dessiné à la main. Chaque image est décomposée en un quadrillage de 28 x 28 \"cases\", chaque case étant associée à une valeur de pixel. **x_train** est donc une **matrice 3D de shape: 60 000 x 28 x 28**. Chaque indice de zero à 59 000 de x_train correspond ainsi à une matrice 2D de 28 listes de 28 valeurs, chaque valeur correspondant au nombre de pixels compris entre environ 0 et 250. Pour chaque indice de 0 à 59 000 la valeur de **y_train** correspondante est le **label/la classe** (et l'output) de l'image: soit **un chiffre de 1 à 10**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() # chargement du jeu de données\n",
    "\n",
    "# (x_train, y_train) = training set : jeu de données utilisé pour la phase d'apprentissage du cnn\n",
    "# (x_test, y_test) = testing set : jeu de données utilisé pour la phase de test du cnn (vérification de sa fiabilité)\n",
    "\n",
    "\n",
    "## Visualisation du jeu de données:\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(x_train.shape)\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print(x_train[59000])\n",
    "print(y_train[59000])\n",
    "plt.imshow(x_train[59000], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalisation des données inputs entre 0 et 1 (vivement conseillé)\n",
    "\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1)\n",
    "\n",
    "## Visualisation du jeu de données après normalisation:\n",
    "\n",
    "print(x_train[0])\n",
    "print(y_train[0])\n",
    "plt.imshow(x_train[0], cmap = plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print(x_train[59000])\n",
    "print(y_train[59000])\n",
    "plt.imshow(x_train[59000], cmap = plt.cm.binary)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Définition du modèle (= architecture du cnn) avec keras ##\n",
    "\n",
    "model = tf.keras.models.Sequential() # modèle sequentiel\n",
    "model.add(tf.keras.layers.Flatten()) # input layer --> reshaped à une dimension (et non plus 2D (matrice 28 x 28))\n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) # 1st inner layer definition : 128 neurones \n",
    "model.add(tf.keras.layers.Dense(128, activation = tf.nn.relu)) # 2nd inner layer definition : 128 neurones\n",
    "# dense par opposition à flatten : plusieurs dimensions pour l'input reçu \n",
    "# Par défaut c'est la fonction d'activation ReLu (si x < 0, y = 0; si x >= 0, y = x) qui est utilisé pour les inner layers\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax)) # outpout layer\n",
    "# Nombre de neurones = nombre de classes/outputs possibles : ici 10\n",
    "# Pour un cnn utilisé pour faire de la classification (= probability distribution) c'est la fontion softmax qu'on utilise comme fonction d'activation de l'oupout layer\n",
    "\n",
    "## définition des paramètres de training du modèle:\n",
    "model.compile(optimizer = 'adam', # adam est l'optimizer par défaut\n",
    "              loss = 'sparse_categorical_crossentropy', # loss aurait pu être binary pour une classification à 2 classes\n",
    "              metrics = ['accuracy'])\n",
    "## Training:\n",
    "model.fit(x_train, y_train, epochs = 3)\n",
    "\n",
    "## \" Epoch is just a \"full pass\" through the entire training dataset. \n",
    "## So if we train on 1 epoch, the neural network sees each unique sample once. \n",
    "## 3 epochs means it passed over our data set 3 times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer l'accuracy qui augmente après chaque epoch avec la perte loss qui diminue en parallèle.\n",
    "Rappel le but du cnn est de minimser la perte loss en s'entraînant\n",
    "Le risque avec un cnn c'est d'avantage l'overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
